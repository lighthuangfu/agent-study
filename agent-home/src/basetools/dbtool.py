# -*- coding: utf-8 -*-
import os
from typing import List, Optional
from qdrant_client import QdrantClient
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.embeddings import Embeddings

# å°è¯•å¯¼å…¥ä¸åŒçš„ embedding æ¨¡å‹
try:
    from langchain_community.embeddings import HuggingFaceEmbeddings
    HUGGINGFACE_AVAILABLE = True
except ImportError:
    HUGGINGFACE_AVAILABLE = False

try:
    from langchain_openai import OpenAIEmbeddings
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

QDRANT_URL = os.getenv("QDRANT_URL", "http://localhost:6333")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")

def _get_qdrant_client() -> QdrantClient:
    """
    å†…éƒ¨å¸®åŠ©å‡½æ•°ï¼šæ„é€  QdrantClientã€‚
    é»˜è®¤è¿æ¥æœ¬åœ° 6333 ç«¯å£ï¼Œæ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼š
    - QDRANT_URL
    - QDRANT_API_KEY
    """
    return QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)


# åˆå§‹åŒ–æ–‡æœ¬åˆ†å‰²å™¨ï¼ˆä½¿ç”¨ LangChain çš„æ ‡å‡†åˆ†å‰²å™¨ï¼‰
_text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,           # æ¯ä¸ª chunk çš„æœ€å¤§å­—ç¬¦æ•°
    chunk_overlap=50,         # chunk ä¹‹é—´çš„é‡å å­—ç¬¦æ•°ï¼ˆä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§ï¼‰
    length_function=len,      # è®¡ç®—é•¿åº¦çš„å‡½æ•°
    separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "!", "?", " ", ""],  # åˆ†å‰²ç¬¦ä¼˜å…ˆçº§ï¼ˆä¸­æ–‡å‹å¥½ï¼‰
)


def _split_text_into_chunks(text: str, max_len: int = 500) -> List[str]:
    """
    ä½¿ç”¨ LangChain çš„ RecursiveCharacterTextSplitter åˆ‡åˆ†æ–‡æœ¬ã€‚
    
    å‚æ•°:
        text: è¦åˆ‡åˆ†çš„æ–‡æœ¬
        max_len: æ¯ä¸ª chunk çš„æœ€å¤§é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰
    
    è¿”å›:
        æ–‡æœ¬ç‰‡æ®µåˆ—è¡¨
    """
    if not text:
        return []
    
    # å¦‚æœæŒ‡å®šäº†ä¸åŒçš„ max_lenï¼Œåˆ›å»ºæ–°çš„åˆ†å‰²å™¨
    if max_len != 500:
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=max_len,
            chunk_overlap=min(50, max_len // 10),  # é‡å ä¸º chunk_size çš„ 10%ï¼Œæœ€å¤š 50
            length_function=len,
            separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "!", "?", " ", ""],
        )
        chunks = splitter.split_text(text)
    else:
        chunks = _text_splitter.split_text(text)
    
    return chunks


def _get_embedding_model() -> Embeddings:
    """
    è·å– embedding æ¨¡å‹å®ä¾‹ã€‚
    
    ä¼˜å…ˆçº§ï¼š
    1. å¦‚æœè®¾ç½®äº† EMBEDDING_MODEL ç¯å¢ƒå˜é‡ï¼Œä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹
    2. å¦‚æœå¯ç”¨ï¼Œä¼˜å…ˆä½¿ç”¨ HuggingFaceï¼ˆå…è´¹ï¼Œæœ¬åœ°è¿è¡Œï¼Œæ”¯æŒä¸­æ–‡ï¼‰
    3. å¦‚æœè®¾ç½®äº† OPENAI_API_KEYï¼Œä½¿ç”¨ OpenAI Embeddings
    4. å¦åˆ™å›é€€åˆ°ç®€å•çš„å“ˆå¸Œ embeddingï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰
    
    è¿”å›:
        Embeddings å®ä¾‹
    """
    # æ£€æŸ¥æ˜¯å¦æŒ‡å®šäº† embedding æ¨¡å‹
    embedding_model = os.getenv("EMBEDDING_MODEL", "").lower()
    
    # æ–¹æ¡ˆ1ï¼šä½¿ç”¨ HuggingFaceï¼ˆæ¨èï¼Œå…è´¹ä¸”æ”¯æŒä¸­æ–‡ï¼‰
    if HUGGINGFACE_AVAILABLE and (embedding_model in ("", "huggingface", "hf")):
        try:
            # ä½¿ç”¨ä¸­æ–‡ä¼˜åŒ–çš„æ¨¡å‹ï¼Œå¦‚æœæ²¡æœ‰ä¼šè‡ªåŠ¨ä¸‹è½½
            # å¯é€‰æ¨¡å‹ï¼š
            # - "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2" (å¤šè¯­è¨€ï¼Œ384ç»´)
            # - "sentence-transformers/paraphrase-multilingual-mpnet-base-v2" (å¤šè¯­è¨€ï¼Œ768ç»´)
            # - "shibing624/text2vec-base-chinese" (ä¸­æ–‡ä¸“ç”¨ï¼Œ768ç»´)
            model_name = os.getenv(
                "HUGGINGFACE_EMBEDDING_MODEL",
                "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
            )
            print(f"ğŸŸ¢ ä½¿ç”¨ HuggingFace Embedding æ¨¡å‹: {model_name}")
            return HuggingFaceEmbeddings(
                model_name=model_name,
                model_kwargs={"device": "cpu"},  # ä½¿ç”¨ CPUï¼Œå¦‚æœæœ‰ GPU å¯æ”¹ä¸º "cuda"
                encode_kwargs={"normalize_embeddings": True}  # å½’ä¸€åŒ–å‘é‡
            )
        except Exception as e:
            print(f"âš ï¸ HuggingFace Embedding åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå›é€€åˆ°ç®€å•å“ˆå¸Œæ–¹æ³•")
    
    # æ–¹æ¡ˆ2ï¼šä½¿ç”¨ OpenAI Embeddingsï¼ˆéœ€è¦ API Keyï¼‰
    if OPENAI_AVAILABLE and (embedding_model in ("openai", "gpt")):
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            print("ğŸŸ¢ ä½¿ç”¨ OpenAI Embedding æ¨¡å‹")
            return OpenAIEmbeddings(
                model="text-embedding-3-small",  # æˆ– "text-embedding-3-large"
                openai_api_key=api_key
            )
        else:
            print("âš ï¸ æœªè®¾ç½® OPENAI_API_KEYï¼Œå›é€€åˆ°ç®€å•å“ˆå¸Œæ–¹æ³•")
    
    # æ–¹æ¡ˆ3ï¼šå›é€€åˆ°ç®€å•çš„å“ˆå¸Œæ–¹æ³•ï¼ˆä»…ç”¨äºæµ‹è¯•/æ¼”ç¤ºï¼‰
    print("âš ï¸ ä½¿ç”¨ç®€å•çš„å“ˆå¸Œ Embeddingï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰ï¼Œå»ºè®®é…ç½® HuggingFace æˆ– OpenAI")
    return _SimpleHashEmbeddings(dimension=384)


class _SimpleHashEmbeddings(Embeddings):
    """
    ç®€å•çš„å“ˆå¸Œ embedding å®ç°ï¼ˆä»…ä½œä¸ºå›é€€æ–¹æ¡ˆï¼‰ã€‚
    è¿™ä¸æ˜¯çœŸæ­£çš„è¯­ä¹‰å‘é‡ï¼Œä»…ç”¨äºæµ‹è¯•å’Œæ¼”ç¤ºã€‚
    """
    
    def __init__(self, dimension: int = 384):
        self.dimension = dimension
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """åµŒå…¥æ–‡æ¡£åˆ—è¡¨ã€‚"""
        return [self._embed_text(text) for text in texts]
    
    def embed_query(self, text: str) -> List[float]:
        """åµŒå…¥æŸ¥è¯¢æ–‡æœ¬ã€‚"""
        return self._embed_text(text)
    
    def _embed_text(self, text: str) -> List[float]:
        """å†…éƒ¨æ–¹æ³•ï¼šå°†å•ä¸ªæ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ã€‚"""
        import math
        vec = [0.0] * self.dimension
        if not text:
            return vec
        
        for ch in text:
            idx = hash(ch) % self.dimension
            vec[idx] += 1.0
        
        # ç®€å•å½’ä¸€åŒ–
        norm = math.sqrt(sum(v * v for v in vec)) or 1.0
        return [v / norm for v in vec]


# åˆ›å»ºå…¨å±€ embedding å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
_default_embedding: Optional[Embeddings] = None


def _get_default_embedding() -> Embeddings:
    """è·å–é»˜è®¤çš„ embedding å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰ã€‚"""
    global _default_embedding
    if _default_embedding is None:
        _default_embedding = _get_embedding_model()
    return _default_embedding


def _simple_hash_embedding(text: str, dim: int = 384) -> List[float]:
    """
    æ–‡æœ¬å‘é‡åŒ–å‡½æ•°ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰ã€‚
    
    ç°åœ¨ä½¿ç”¨æˆç†Ÿçš„ embedding æ¨¡å‹ï¼ˆHuggingFace/OpenAIï¼‰ï¼Œè€Œä¸æ˜¯ç®€å•çš„å“ˆå¸Œã€‚
    
    å‚æ•°:
        text: è¦å‘é‡åŒ–çš„æ–‡æœ¬
        dim: å‘é‡ç»´åº¦ï¼ˆæ³¨æ„ï¼šå®é™…ç»´åº¦å–å†³äºä½¿ç”¨çš„ embedding æ¨¡å‹ï¼Œæ­¤å‚æ•°ä¿ç•™ç”¨äºå…¼å®¹æ€§ï¼‰
    
    è¿”å›:
        å‘é‡åˆ—è¡¨
    """
    embedding = _get_default_embedding()
    return embedding.embed_query(text)


def _embed_documents(texts: List[str]) -> List[List[float]]:
    """
    æ‰¹é‡å‘é‡åŒ–æ–‡æ¡£åˆ—è¡¨ï¼ˆæ›´é«˜æ•ˆï¼‰ã€‚
    
    å‚æ•°:
        texts: è¦å‘é‡åŒ–çš„æ–‡æœ¬åˆ—è¡¨
    
    è¿”å›:
        å‘é‡åˆ—è¡¨çš„åˆ—è¡¨
    """
    if not texts:
        return []
    embedding = _get_default_embedding()
    return embedding.embed_documents(texts)